{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from sklearn.metrics import classification_report, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/b1/016e657586843f40b4daa66127ce1ee9e3285ff15baf5d80946644a98aeb/graphviz-0.11.1-py2.py3-none-any.whl\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.11.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#!pip install graphviz\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform as sp_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines = pd.read_csv('data/strongdrink.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "0         1  14.23   1.71  2.43  15.6   127      2.80  3.06        0.28   \n",
       "1         1  13.20   1.78  2.14  11.2   100      2.65  2.76        0.26   \n",
       "2         1  13.16   2.36  2.67  18.6   101      2.80  3.24        0.30   \n",
       "3         1  14.37   1.95  2.50  16.8   113      3.85  3.49        0.24   \n",
       "4         1  13.24   2.59  2.87  21.0   118      2.80  2.69        0.39   \n",
       "\n",
       "   proanth  color_int   hue  OD280rat  proline  \n",
       "0     2.29       5.64  1.04      3.92     1065  \n",
       "1     1.28       4.38  1.05      3.40     1050  \n",
       "2     2.81       5.68  1.03      3.17     1185  \n",
       "3     2.18       7.80  0.86      3.45     1480  \n",
       "4     1.82       4.32  1.04      2.93      735  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wines[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "y = wines['cultivar'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultLogReg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-24.02761485  22.78073088]\n",
      "[[ 1.70173414 -0.26578736  1.2241009   0.02250728]\n",
      " [-1.46629727 -0.33295097  0.66355617 -0.9226817 ]]\n"
     ]
    }
   ],
   "source": [
    "print(MultLogReg.intercept_[0:2])\n",
    "print(MultLogReg.coef_[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.90      0.95        21\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        44\n",
      "   macro avg       0.96      0.97      0.96        44\n",
      "weighted avg       0.96      0.95      0.96        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=MultLogReg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    46\n",
       "Name: cultivar, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines['cultivar'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes 2 and 3 have the lowest error rates (i.e. 1 - precision, as reported above). Based on the f1-score, the model predicts class 3 best. Class 3, nonetheless, has the least number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set MSE =  0.045454545454545456\n"
     ]
    }
   ],
   "source": [
    "print('Validation set MSE = ', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_loo = X.shape[0]\n",
    "LeaveOneOut().get_n_splits(X)\n",
    "MSE_vec = np.zeros(N_loo)\n",
    "y_pred = np.zeros(N_loo)\n",
    "\n",
    "for train_index, test_index in LeaveOneOut().split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    MultLogReg = LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial')\n",
    "    MultLogReg.fit(X_train, y_train)\n",
    "    y_pred[test_index] = MultLogReg.predict(X_test)\n",
    "    MSE_vec[test_index] = (y_test - y_pred[test_index]) ** 2\n",
    "    #print('MSE for test set', test_index, ' is', MSE_vec[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.93      0.92        59\n",
      "           2       0.91      0.90      0.91        71\n",
      "           3       0.96      0.93      0.95        46\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       176\n",
      "   macro avg       0.92      0.92      0.92       176\n",
      "weighted avg       0.92      0.92      0.92       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE loocv= 0.09659090909090909 , test estimate MSE standard err= 0.39426250589387657\n"
     ]
    }
   ],
   "source": [
    "MSE_loo = MSE_vec.mean()\n",
    "MSE_loo_std = MSE_vec.std()\n",
    "print('test estimate MSE loocv=', MSE_loo,\n",
    "      ', test estimate MSE standard err=', MSE_loo_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rates have increased for two out of three classes (namely, class 2 and 3) relative to Exercise 1.A. This underpins the concern that one should not simply rely on one draw to form conclusions about model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_pred = np.zeros_like(y)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    MultLogReg = LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial')\n",
    "    MultLogReg.fit(X_train, y_train)\n",
    "    y_pred[test_index] = MultLogReg.predict(X_test)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred[test_index]) ** 2).mean()\n",
    "    \n",
    "    k_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.90      0.90        59\n",
      "           2       0.90      0.90      0.90        71\n",
      "           3       0.93      0.93      0.93        46\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       176\n",
      "   macro avg       0.91      0.91      0.91       176\n",
      "weighted avg       0.91      0.91      0.91       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE k-fold= 0.12375478927203064 test estimate MSE standard err= 0.08696642841787021\n"
     ]
    }
   ],
   "source": [
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print('test estimate MSE k-fold=', MSE_kf,\n",
    "      'test estimate MSE standard err=', MSE_kf_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden = pd.read_csv('data/biden.csv')\n",
    "biden = biden.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biden</th>\n",
       "      <th>female</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>dem</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   biden  female  age  educ  dem  rep\n",
       "0     90       0   19    12    1    0\n",
       "1     70       1   51    14    1    0\n",
       "2     60       0   27    14    0    0\n",
       "3     50       1   43    14    1    0\n",
       "4     60       1   38    14    0    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = biden[['female', 'age', 'educ', 'dem', 'rep']].values\n",
    "y = biden['biden'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=5,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tree = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\n",
    "biden_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"1038pt\" height=\"373pt\"\r\n",
       " viewBox=\"0.00 0.00 1038.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-369 1034,-369 1034,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.568627\" stroke=\"black\" d=\"M562,-365C562,-365 467,-365 467,-365 461,-365 455,-359 455,-353 455,-353 455,-309 455,-309 455,-303 461,-297 467,-297 467,-297 562,-297 562,-297 568,-297 574,-303 574,-309 574,-309 574,-353 574,-353 574,-359 568,-365 562,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"514.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[3] &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"514.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 556.262</text>\r\n",
       "<text text-anchor=\"middle\" x=\"514.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1264</text>\r\n",
       "<text text-anchor=\"middle\" x=\"514.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 62.165</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.345098\" stroke=\"black\" d=\"M428,-261C428,-261 339,-261 339,-261 333,-261 327,-255 327,-249 327,-249 327,-205 327,-205 327,-199 333,-193 339,-193 339,-193 428,-193 428,-193 434,-193 440,-199 440,-205 440,-205 440,-249 440,-249 440,-255 434,-261 428,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[4] &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 507.397</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 724</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 52.811</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M471.968,-296.884C459.956,-287.531 446.764,-277.259 434.318,-267.568\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"436.307,-264.681 426.267,-261.299 432.007,-270.205 436.307,-264.681\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"429.355\" y=\"-282.408\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.866667\" stroke=\"black\" d=\"M690,-261C690,-261 601,-261 601,-261 595,-261 589,-255 589,-249 589,-249 589,-205 589,-205 589,-199 595,-193 601,-193 601,-193 690,-193 690,-193 696,-193 702,-199 702,-205 702,-205 702,-249 702,-249 702,-255 696,-261 690,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[1] &lt;= 54.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 347.197</text>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 540</text>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 74.706</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>0&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557.032,-296.884C569.044,-287.531 582.236,-277.259 594.682,-267.568\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"596.993,-270.205 602.733,-261.299 592.693,-264.681 596.993,-270.205\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"599.645\" y=\"-282.408\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.490196\" stroke=\"black\" d=\"M232,-157C232,-157 143,-157 143,-157 137,-157 131,-151 131,-145 131,-145 131,-101 131,-101 131,-95 137,-89 143,-89 143,-89 232,-89 232,-89 238,-89 244,-95 244,-101 244,-101 244,-145 244,-145 244,-151 238,-157 232,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 444.551</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 468</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 58.868</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326.809,-196.497C303.751,-184.498 276.959,-170.555 253.065,-158.121\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.55,-154.948 244.064,-153.436 251.319,-161.157 254.55,-154.948\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.082353\" stroke=\"black\" d=\"M428,-157C428,-157 339,-157 339,-157 333,-157 327,-151 327,-145 327,-145 327,-101 327,-101 327,-95 333,-89 339,-89 339,-89 428,-89 428,-89 434,-89 440,-95 440,-101 440,-101 440,-145 440,-145 440,-151 434,-157 428,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 432.623</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 256</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 41.738</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383.5,-192.884C383.5,-184.778 383.5,-175.982 383.5,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"387,-167.299 383.5,-157.299 380,-167.299 387,-167.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.431373\" stroke=\"black\" d=\"M101,-53C101,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 101,-0 101,-0 107,-0 113,-6 113,-12 113,-12 113,-41 113,-41 113,-47 107,-53 101,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 470.335</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 235</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 56.489</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.683,-88.9485C128.367,-79.3431 113.855,-68.8747 100.645,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.335,-56.2486 92.1773,-53.2367 98.2398,-61.9257 102.335,-56.2486\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.545098\" stroke=\"black\" d=\"M232,-53C232,-53 143,-53 143,-53 137,-53 131,-47 131,-41 131,-41 131,-12 131,-12 131,-6 137,-0 143,-0 143,-0 232,-0 232,-0 238,-0 244,-6 244,-12 244,-12 244,-41 244,-41 244,-47 238,-53 232,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 407.088</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 233</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 61.266</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.5,-88.9485C187.5,-80.7153 187.5,-71.848 187.5,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191,-63.2367 187.5,-53.2367 184,-63.2367 191,-63.2367\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M363,-53C363,-53 274,-53 274,-53 268,-53 262,-47 262,-41 262,-41 262,-12 262,-12 262,-6 268,-0 274,-0 274,-0 363,-0 363,-0 369,-0 375,-6 375,-12 375,-12 375,-41 375,-41 375,-47 369,-53 363,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"318.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 456.775</text>\r\n",
       "<text text-anchor=\"middle\" x=\"318.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 123</text>\r\n",
       "<text text-anchor=\"middle\" x=\"318.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 38.333</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M360.766,-88.9485C354.663,-80.0749 348.053,-70.4648 341.913,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"344.753,-59.4924 336.202,-53.2367 338.986,-63.4594 344.753,-59.4924\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.156863\" stroke=\"black\" d=\"M494,-53C494,-53 405,-53 405,-53 399,-53 393,-47 393,-41 393,-41 393,-12 393,-12 393,-6 399,-0 405,-0 405,-0 494,-0 494,-0 500,-0 506,-6 506,-12 506,-12 506,-41 506,-41 506,-47 500,-53 494,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 389.649</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 133</text>\r\n",
       "<text text-anchor=\"middle\" x=\"449.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 44.887</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M406.584,-88.9485C412.781,-80.0749 419.493,-70.4648 425.727,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"428.669,-63.4392 431.525,-53.2367 422.93,-59.4311 428.669,-63.4392\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.815686\" stroke=\"black\" d=\"M690,-157C690,-157 601,-157 601,-157 595,-157 589,-151 589,-145 589,-145 589,-101 589,-101 589,-95 595,-89 601,-89 601,-89 690,-89 690,-89 696,-89 702,-95 702,-101 702,-101 702,-145 702,-145 702,-151 696,-157 690,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[2] &lt;= 15.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 345.027</text>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 340</text>\r\n",
       "<text text-anchor=\"middle\" x=\"645.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 72.606</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M645.5,-192.884C645.5,-184.778 645.5,-175.982 645.5,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"649,-167.299 645.5,-157.299 642,-167.299 649,-167.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.952941\" stroke=\"black\" d=\"M887,-157C887,-157 798,-157 798,-157 792,-157 786,-151 786,-145 786,-145 786,-101 786,-101 786,-95 792,-89 798,-89 798,-89 887,-89 887,-89 893,-89 899,-95 899,-101 899,-101 899,-145 899,-145 899,-151 893,-157 887,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"842.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X[0] &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"842.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 330.649</text>\r\n",
       "<text text-anchor=\"middle\" x=\"842.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 200</text>\r\n",
       "<text text-anchor=\"middle\" x=\"842.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 78.275</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>8&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M702.216,-196.634C725.499,-184.579 752.605,-170.545 776.749,-158.044\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"778.572,-161.041 785.843,-153.335 775.353,-154.825 778.572,-161.041\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.780392\" stroke=\"black\" d=\"M625,-53C625,-53 536,-53 536,-53 530,-53 524,-47 524,-41 524,-41 524,-12 524,-12 524,-6 530,-0 536,-0 536,-0 625,-0 625,-0 631,-0 637,-6 637,-12 637,-12 637,-41 637,-41 637,-47 631,-53 625,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"580.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 369.301</text>\r\n",
       "<text text-anchor=\"middle\" x=\"580.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 247</text>\r\n",
       "<text text-anchor=\"middle\" x=\"580.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 71.105</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>9&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.766,-88.9485C616.663,-80.0749 610.053,-70.4648 603.913,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"606.753,-59.4924 598.202,-53.2367 600.986,-63.4594 606.753,-59.4924\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.913725\" stroke=\"black\" d=\"M756,-53C756,-53 667,-53 667,-53 661,-53 655,-47 655,-41 655,-41 655,-12 655,-12 655,-6 661,-0 667,-0 667,-0 756,-0 756,-0 762,-0 768,-6 768,-12 768,-12 768,-41 768,-41 768,-47 762,-53 756,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 258.693</text>\r\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 93</text>\r\n",
       "<text text-anchor=\"middle\" x=\"711.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 76.591</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>9&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M668.584,-88.9485C674.781,-80.0749 681.493,-70.4648 687.727,-61.5388\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"690.669,-63.4392 693.525,-53.2367 684.93,-59.4311 690.669,-63.4392\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.878431\" stroke=\"black\" d=\"M887,-53C887,-53 798,-53 798,-53 792,-53 786,-47 786,-41 786,-41 786,-12 786,-12 786,-6 792,-0 798,-0 798,-0 887,-0 887,-0 893,-0 899,-6 899,-12 899,-12 899,-41 899,-41 899,-47 893,-53 887,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"842.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 399.015</text>\r\n",
       "<text text-anchor=\"middle\" x=\"842.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 79</text>\r\n",
       "<text text-anchor=\"middle\" x=\"842.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 75.19</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M842.5,-88.9485C842.5,-80.7153 842.5,-71.848 842.5,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"846,-63.2367 842.5,-53.2367 839,-63.2367 846,-63.2367\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1018,-53C1018,-53 929,-53 929,-53 923,-53 917,-47 917,-41 917,-41 917,-12 917,-12 917,-6 923,-0 929,-0 929,-0 1018,-0 1018,-0 1024,-0 1030,-6 1030,-12 1030,-12 1030,-41 1030,-41 1030,-47 1024,-53 1018,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"973.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 275.743</text>\r\n",
       "<text text-anchor=\"middle\" x=\"973.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 121</text>\r\n",
       "<text text-anchor=\"middle\" x=\"973.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 80.289</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>12&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M888.317,-88.9485C901.633,-79.3431 916.145,-68.8747 929.355,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"931.76,-61.9257 937.823,-53.2367 927.665,-56.2486 931.76,-61.9257\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x210a3cafef0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tree_viz = export_graphviz(\n",
    "    biden_tree,\n",
    "    out_file=None,\n",
    "    #feature_names=biden.feature_names[2:],\n",
    "    # class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(biden_tree_viz)\n",
    "graph.render('biden_tree_viz')\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE= 396.1937146321307\n"
     ]
    }
   ],
   "source": [
    "y_pred = biden_tree.predict(X_test)\n",
    "MSE1 = mean_squared_error(y_test, y_pred)\n",
    "print('MSE=', MSE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator = DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=17,\n",
      "           min_samples_split=14, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      "Best Parameters = {'max_depth': 3, 'min_samples_leaf': 17, 'min_samples_split': 14}\n",
      "Best Score = 401.6903602232667\n"
     ]
    }
   ],
   "source": [
    "param_dist1 = {'max_depth': [3, 10],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20)}\n",
    "\n",
    "biden_tree2 = DecisionTreeRegressor()\n",
    "\n",
    "random_search1 = RandomizedSearchCV(biden_tree2, param_distributions=param_dist1, n_iter=100, n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search1.fit(X, y)\n",
    "print('Best Estimator =', random_search1.best_estimator_)\n",
    "print('Best Parameters =', random_search1.best_params_)\n",
    "print('Best Score =', -random_search1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator =  RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "           max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=17,\n",
      "           min_samples_split=13, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=None, oob_score=True, random_state=25,\n",
      "           verbose=0, warm_start=False)\n",
      "Best Parameters =  {'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 17, 'min_samples_split': 13, 'n_estimators': 10}\n",
      "Best Score = 397.0681090117028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:732: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "param_dist2 = { 'n_estimators': [10, 200],\n",
    "                'max_depth': [3, 10],\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 5)}\n",
    "\n",
    "biden_forest = RandomForestRegressor(bootstrap=True,oob_score=True, random_state=25)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(biden_forest, param_distributions=param_dist2, n_iter=100, n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search2.fit(X, y)\n",
    "print('Best Estimator = ', random_search2.best_estimator_)\n",
    "print('Best Parameters = ', random_search2.best_params_)\n",
    "print('Best Score =', -random_search2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos = pd.read_csv('data/Auto.csv', na_values=['?'])\n",
    "autos = autos.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = autos['mpg'].median()\n",
    "autos['mpg_high'] = (autos['mpg'] >= med).astype(int)\n",
    "\n",
    "autos['const'] = 1\n",
    "\n",
    "autos['orgn1'] = (autos['origin'] == 1).astype(int)\n",
    "autos['orgn2'] = (autos['origin'] == 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>mpg_high</th>\n",
       "      <th>const</th>\n",
       "      <th>orgn1</th>\n",
       "      <th>orgn2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   origin                       name  mpg_high  const  orgn1  orgn2  \n",
       "0       1  chevrolet chevelle malibu         0      1      1      0  \n",
       "1       1          buick skylark 320         0      1      1      0  \n",
       "2       1         plymouth satellite         0      1      1      0  \n",
       "3       1              amc rebel sst         0      1      1      0  \n",
       "4       1                ford torino         0      1      1      0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = autos[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'orgn1', 'orgn2']].values\n",
    "y = autos['mpg_high'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=25)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "MSE_vec_kf_high = np.zeros(k)\n",
    "MSE_vec_kf_low = np.zeros(k)\n",
    "y_pred = np.zeros_like(y)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    LogReg = LogisticRegression(solver='liblinear')\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred[test_index] = LogReg.predict(X_test)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred[test_index]) ** 2).mean()\n",
    "    \n",
    "    MSE_vec_kf_high[k_ind] = sum((y_test != y_pred[test_index]) * (y_test == 0)) / sum(y_test == 0)\n",
    "    MSE_vec_kf_low[k_ind] = sum((y_test != y_pred[test_index]) * (y_test == 1)) / sum(y_test == 1)\n",
    "    \n",
    "    k_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       196\n",
      "           1       0.89      0.92      0.90       196\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       392\n",
      "   macro avg       0.90      0.90      0.90       392\n",
      "weighted avg       0.90      0.90      0.90       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE k-fold= 0.09693877551020408 test estimate MSE standard err= 0.027475330648645428\n"
     ]
    }
   ],
   "source": [
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print('test estimate MSE k-fold=', MSE_kf,\n",
    "      'test estimate MSE standard err=', MSE_kf_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE k-fold (high)= 0.11364706285146922 test estimate MSE standard err (high)= 0.01617468606029206\n",
      "test estimate MSE k-fold (low)= 0.07941477339674582 test estimate MSE standard err (low)= 0.0395630343839898\n"
     ]
    }
   ],
   "source": [
    "MSE_kf_high = MSE_vec_kf_high.mean()\n",
    "MSE_kf_high_std = MSE_vec_kf_high.std()\n",
    "print('test estimate MSE k-fold (high)=', MSE_kf_high,\n",
    "      'test estimate MSE standard err (high)=', MSE_kf_high_std)\n",
    "\n",
    "MSE_kf_low = MSE_vec_kf_low.mean()\n",
    "MSE_kf_low_std = MSE_vec_kf_low.std()\n",
    "print('test estimate MSE k-fold (low)=', MSE_kf_low,\n",
    "      'test estimate MSE standard err (low)=', MSE_kf_low_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=True, random_state=25, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [10, 200], 'max_depth': [3, 8], 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000210A4112BA8>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000210A41121D0>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000210A4112D68>},\n",
       "          pre_dispatch='2*n_jobs', random_state=25, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist3 = { 'n_estimators': [10, 200],\n",
    "                'max_depth': [3, 8],\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 8)}\n",
    "\n",
    "mpg_forest = RandomForestClassifier(bootstrap=True, oob_score=True, random_state=25)\n",
    "\n",
    "random_search3 = RandomizedSearchCV(mpg_forest, param_distributions=param_dist3, n_iter=100, n_jobs=-1, cv=4, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator =  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=8, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=15, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=True, random_state=25, verbose=0, warm_start=False)\n",
      "Best Parameters =  {'max_depth': 8, 'max_features': 3, 'min_samples_leaf': 15, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best Score = 0.08928571428571429\n"
     ]
    }
   ],
   "source": [
    "print('Best Estimator = ', random_search3.best_estimator_)\n",
    "print('Best Parameters = ', random_search3.best_params_)\n",
    "print('Best Score =', -random_search3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator =  SVC(C=1.8094629152568114, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
      "  tol=0.001, verbose=False)\n",
      "Best Parameters =  {'C': 1.8094629152568114, 'gamma': 'scale', 'shrinking': False}\n",
      "Best Score = 0.11479591836734694\n"
     ]
    }
   ],
   "source": [
    "param_dist4 = { 'C': sp_uniform(loc=0.2, scale=4.0),\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'shrinking': [True, False]}\n",
    "\n",
    "mpg_SVM = SVC(kernel='rbf')\n",
    "\n",
    "random_search4 = RandomizedSearchCV(mpg_SVM, param_distributions=param_dist4, n_iter=100, n_jobs=-1, cv=4, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search4.fit(X, y)\n",
    "print('Best Estimator = ', random_search4.best_estimator_)\n",
    "print('Best Parameters = ', random_search4.best_params_)\n",
    "print('Best Score =', -random_search4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest approach results in the lowest MSE, hence it is the best model to predict \"mpg_high\" given the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines = pd.read_csv('data/strongdrink.txt')\n",
    "X = wines[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "y = wines['cultivar'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {1:'red', 2:'blue', 3:'green'}\n",
    "for i in range(1,4):\n",
    "    df = wines[wines['cultivar'] == i]\n",
    "    plt.scatter(df['alco'], df['color_int'], c=colors[i], label=i)\n",
    "\n",
    "plt.xlabel(\"Alcohol\") \n",
    "plt.ylabel(\"Color Intensity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters =  {'C': 1.9591123209017924, 'penalty': 'l1'}\n",
      "Best Score = 0.17045454545454544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "param_dist1 = {'penalty': ['l1', 'l2'],\n",
    "               'C': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "MultLogReg = LogisticRegression(solver='saga', multi_class='multinomial')\n",
    "random_search1 = RandomizedSearchCV(MultLogReg, param_distributions=param_dist1, n_iter=200, n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search1.fit(X, y)\n",
    "\n",
    "print('Best Parameters = ', random_search1.best_params_)\n",
    "print('Best Score =', -random_search1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters =  {'max_depth': 3, 'max_features': 1, 'min_samples_leaf': 6, 'min_samples_split': 7, 'n_estimators': 139}\n",
      "Best Score = 0.13068181818181818\n"
     ]
    }
   ],
   "source": [
    "param_dist2 = { 'n_estimators': sp_randint(10, 200),\n",
    "                'max_depth': sp_randint(2, 4),\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 4)}\n",
    "\n",
    "Forest = RandomForestClassifier(bootstrap=True, oob_score=True)\n",
    "random_search2 = RandomizedSearchCV(Forest, param_distributions=param_dist2, n_iter=200, n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search2.fit(X, y)\n",
    "\n",
    "print('Best Parameters = ', random_search2.best_params_)\n",
    "print('Best Score =', -random_search2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters =  {'C': 3.3605112613782553, 'gamma': 'scale', 'shrinking': True}\n",
      "Best Score = 0.14772727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "param_dist3 = { 'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'shrinking': [True, False]}\n",
    "\n",
    "SVC_wines = SVC(kernel='rbf')\n",
    "random_search3 = RandomizedSearchCV(SVC_wines, param_distributions=param_dist3, n_iter=200, n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search3.fit(X, y)\n",
    "\n",
    "print('Best Parameters = ', random_search3.best_params_)\n",
    "print('Best Score =', -random_search3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.E**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woute\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters =  {'activation': 'relu', 'alpha': 0.7965389843643799, 'hidden_layer_sizes': 91}\n",
      "Best Score = 0.08522727272727272\n"
     ]
    }
   ],
   "source": [
    "param_dist4 = {'hidden_layer_sizes': sp_randint(1, 100),\n",
    "                'activation': ['logistic', 'relu'],\n",
    "                'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "Neural_Net = MLPClassifier(solver='lbfgs')\n",
    "random_search4 = RandomizedSearchCV(Neural_Net, param_distributions=param_dist4, n_iter=200, n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search4.fit(X, y)\n",
    "\n",
    "print('Best Parameters = ', random_search4.best_params_)\n",
    "print('Best Score =', -random_search4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.F**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the neural net results in the best score (i.e. lowest MSE), hence it is the best model to predict the respective \"cultivar\" given the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
